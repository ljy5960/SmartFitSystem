import pandas as pd
import numpy as np
import joblib
import os
from xgboost import XGBClassifier
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline


def train_engine():
    print("ğŸš€ [1/4] å¼€å§‹è®­ç»ƒ... (V7: ç‰©ç†è§„å¾‹é”å®šç‰ˆ)")

    # ---------------------------------------------------------
    # 1. é€šç”¨èƒŒæ™¯æ•°æ®
    # ---------------------------------------------------------
    n_samples = 25000
    np.random.seed(42)

    sizes = np.random.randint(0, 26, n_samples)
    heights = np.random.normal(165, 5, n_samples)

    # åŸºç¡€å…¬å¼ï¼šæ ‡å‡†è…°å›´ = 60 + (å°ºç  * 3)
    base_waist = 60 + (sizes * 3.0)

    # === A. åˆèº« (Fit) ===
    waist_fit = base_waist + np.random.uniform(-5, 5, n_samples)
    df_fit = pd.DataFrame(
        {'size': sizes, 'height_cm': heights, 'waist': waist_fit, 'hips': waist_fit * 1.4, 'bra_num': 34,
         'cup_size': 'b', 'category': 'dresses', 'target': 1})

    # === B. åå° (Small) ===
    waist_small = base_waist + np.random.randint(8, 40, n_samples)
    df_small = pd.DataFrame(
        {'size': sizes, 'height_cm': heights, 'waist': waist_small, 'hips': waist_small * 1.4, 'bra_num': 34,
         'cup_size': 'b', 'category': 'dresses', 'target': 0})

    # === C. åå¤§ (Large) - å…³é”®ä¿®æ”¹ ===
    # é€»è¾‘é”ï¼šç¦æ­¢ç”Ÿæˆ Size 0 å’Œ Size 1 çš„åå¤§æ ·æœ¬
    # åªæœ‰å½“ Size >= 2 æ—¶ï¼Œæ‰å…è®¸å‡ºç°â€œè¡£æœå¤ªå¤§â€çš„æƒ…å†µ
    waist_large = base_waist - np.random.randint(8, 30, n_samples)
    waist_large = np.maximum(waist_large, 45)

    df_large = pd.DataFrame({
        'size': sizes, 'height_cm': heights, 'waist': waist_large,
        'hips': waist_large * 1.4, 'bra_num': 34, 'cup_size': 'b',
        'category': 'dresses', 'target': 2
    })

    # è¿‡æ»¤æ‰ Size 0 å’Œ Size 1 çš„ Large æ ·æœ¬
    df_large = df_large[df_large['size'] >= 2]

    # ---------------------------------------------------------
    # 2. â­ï¸ ä¿®å¤ 1: é’ˆå¯¹è…°å›´ 60cm (Size 0-1) çš„ç‰¹è°ƒ
    # ---------------------------------------------------------
    print("ğŸ’‰ æ³¨å…¥å°å°ºç ä¿®æ­£æ•°æ® (Waist 60cm)...")
    fix_data_small = []

    # åœºæ™¯: 60cmè…°å›´ ç©¿ 0ç  (æ ‡å‡†60) -> å¿…é¡»æ˜¯ Fit (1)
    # å¢åŠ æƒé‡åˆ° 5000 æ¡ï¼Œç¡®ä¿è¦†ç›–
    fix_data_small.append(pd.DataFrame({
        'size': [0] * 5000,
        'height_cm': [160] * 5000,  # é…åˆèº«é«˜ 160
        'waist': np.random.normal(60, 0.5, 5000),
        'hips': [85] * 5000, 'bra_num': [32] * 5000, 'cup_size': 'a', 'category': 'dresses',
        'target': 1  # Fit
    }))

    # åœºæ™¯: 60cmè…°å›´ ç©¿ 1ç  (æ ‡å‡†63) -> 60 vs 63 -> ä¹Ÿæ˜¯ Fit (1)
    fix_data_small.append(pd.DataFrame({
        'size': [1] * 5000,
        'height_cm': [160] * 5000,
        'waist': np.random.normal(60, 0.5, 5000),
        'hips': [85] * 5000, 'bra_num': [32] * 5000, 'cup_size': 'a', 'category': 'dresses',
        'target': 1  # Fit
    }))

    # åœºæ™¯: 60cmè…°å›´ ç©¿ 3ç  (æ ‡å‡†69) -> 60 vs 69 -> è¡£æœå¤§äº† -> Large (2)
    fix_data_small.append(pd.DataFrame({
        'size': [3] * 3000,
        'height_cm': [160] * 3000,
        'waist': np.random.normal(60, 0.5, 3000),
        'hips': [85] * 3000, 'bra_num': [32] * 3000, 'cup_size': 'a', 'category': 'dresses',
        'target': 2  # Large
    }))

    # ---------------------------------------------------------
    # 3. â­ï¸ ä¿®å¤ 2: ä¿ç•™é’ˆå¯¹è…°å›´ 78cm (Size 6) çš„æ‰«æ
    # ---------------------------------------------------------
    print("ğŸ’‰ æ³¨å…¥ä¸­å°ºç ä¿®æ­£æ•°æ® (Waist 78cm)...")
    fix_data_mid = []

    # Size 4, 5 -> Small
    for s in [4, 5]:
        fix_data_mid.append(pd.DataFrame({
            'size': [s] * 2000,
            'height_cm': [165] * 2000,
            'waist': np.random.normal(78, 0.5, 2000),
            'hips': [100] * 2000, 'bra_num': [34] * 2000, 'cup_size': 'b', 'category': 'dresses',
            'target': 0
        }))
    # Size 6 -> Fit
    fix_data_mid.append(pd.DataFrame({
        'size': [6] * 4000,
        'height_cm': [165] * 4000,
        'waist': np.random.normal(78, 0.5, 4000),
        'hips': [100] * 4000, 'bra_num': [34] * 4000, 'cup_size': 'b', 'category': 'dresses',
        'target': 1
    }))
    # Size 8 -> Large
    fix_data_mid.append(pd.DataFrame({
        'size': [8] * 2000,
        'height_cm': [165] * 2000,
        'waist': np.random.normal(78, 0.5, 2000),
        'hips': [100] * 2000, 'bra_num': [34] * 2000, 'cup_size': 'b', 'category': 'dresses',
        'target': 2
    }))

    # ---------------------------------------------------------
    # 4. åˆå¹¶ä¸è®­ç»ƒ
    # ---------------------------------------------------------
    df_fix = pd.concat(fix_data_small + fix_data_mid)
    df_final = pd.concat([df_fit, df_small, df_large, df_fix], ignore_index=True)

    df_final['bmi_proxy'] = df_final['waist'] / df_final['height_cm']
    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)

    print(f"âœ… è®­ç»ƒé›†å‡†å¤‡å®Œæ¯•: {len(df_final)} æ¡")

    features = ['cup_size', 'bra_num', 'hips', 'waist', 'category', 'size', 'height_cm', 'bmi_proxy']
    X = df_final[features]
    y = df_final['target']

    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), ['bra_num', 'hips', 'waist', 'size', 'height_cm', 'bmi_proxy']),
        ('cat', OneHotEncoder(handle_unknown='ignore'), ['cup_size', 'category'])
    ])

    pipeline = Pipeline(steps=[
        ('pre', preprocessor),
        # æ·±åº¦é€‚ä¸­ï¼Œé¿å…è¿‡æ‹Ÿåˆ
        ('clf', XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=7))
    ])

    print("ğŸ‹ï¸ [3/4] è®­ç»ƒæ¨¡å‹...")
    pipeline.fit(X, y)

    print("ğŸ’¾ [4/4] ä¿å­˜æ¨¡å‹...")
    if not os.path.exists('models'): os.makedirs('models')
    joblib.dump(pipeline, 'models/fit_model.pkl')
    print("ğŸ‰ V7æ¨¡å‹å·²ä¿å­˜ï¼")


if __name__ == "__main__":
    train_engine()