import pandas as pd
import numpy as np
import joblib
import os
from xgboost import XGBClassifier
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline


def train_engine():
    print("ğŸš€ [1/4] å¼€å§‹è®­ç»ƒ... (V14: å“ç±»å·®å¼‚åŒ–å®¹å¿åº¦ç‰ˆ)")

    # ---------------------------------------------------------
    # 1. å®šä¹‰æ ¸å¿ƒé€»è¾‘ç”Ÿæˆå™¨ (å¸¦å®¹å¿åº¦å‚æ•°)
    # ---------------------------------------------------------
    def generate_batch(category, n_per_combo=20):
        # --- è®¾å®šå“ç±»å®¹å¿åº¦ ---
        if category == 'tops':
            tolerance = 7.0  # ä¸Šè¡£æœ€å®½å®¹ (å…è®¸+7cm)
        elif category == 'dresses':
            tolerance = 6.0  # è¿è¡£è£™ä¸­ç­‰
        else:
            tolerance = 4.0  # ä¸‹è£…æœ€ä¸¥æ ¼ (åªå…è®¸+4cm)

        data_list = []

        # éå†å°ºç  0 åˆ° 18
        for s in range(19):
            # éå†è…°å›´ 50 åˆ° 120
            for w in range(50, 121):

                # æ ‡å‡†å…¬å¼: Size 0=60, Size 3=78
                std_waist = 60 + (s * 6.0)
                diff = w - std_waist

                # --- å·®å¼‚åŒ–åˆ¤å®šé€»è¾‘ ---
                target = 1  # é»˜è®¤ Fit

                if diff > tolerance:
                    target = 0  # Small (äºº > è¡£æœ)
                elif diff < -tolerance:
                    target = 2  # Large (äºº < è¡£æœ)

                # ğŸ›¡ï¸ ç‰©ç†é”ï¼š0ç å’Œ1ç å‡ ä¹ä¸å¯èƒ½ "åå¤§"
                if target == 2 and s <= 1:
                    target = 1

                # --- ç‰¹å¾ç”Ÿæˆ ---
                # ä¸Šè¡£çš„è‡€å›´å½±å“è¾ƒå°
                if category == 'tops':
                    hips_factor = np.random.uniform(1.2, 1.6)
                else:
                    hips_factor = 1.4

                base_bra = 32 + (s // 2) * 2

                batch = pd.DataFrame({
                    'size': [s] * n_per_combo,
                    'height_cm': np.random.uniform(155, 175, n_per_combo),
                    'waist': np.random.normal(w, 0.5, n_per_combo),
                    'hips': np.random.normal(w * hips_factor, 1.0, n_per_combo),
                    'bra_num': np.random.randint(base_bra, base_bra + 4, n_per_combo),
                    'cup_size': np.random.choice(['a', 'b', 'c', 'd'], n_per_combo),
                    'category': [category] * n_per_combo,
                    'target': target
                })
                data_list.append(batch)

        return pd.concat(data_list)

    # ---------------------------------------------------------
    # 2. ç”Ÿæˆæ•°æ®
    # ---------------------------------------------------------
    print("ğŸ§© ç”Ÿæˆ Dresses (Tol=6)...")
    df_dresses = generate_batch('dresses')

    print("ğŸ§© ç”Ÿæˆ Tops (Tol=7)...")
    df_tops = generate_batch('tops')

    print("ğŸ§© ç”Ÿæˆ Bottoms (Tol=4)...")
    df_bottoms = generate_batch('bottoms')

    # ---------------------------------------------------------
    # 3. ğŸ’‰ æ³¨å…¥ç”¨æˆ·ç‰¹ä¾‹ (å…³é”®é”šç‚¹)
    # ---------------------------------------------------------
    print("ğŸ’‰ æ³¨å…¥ç‰¹ä¾‹é”šç‚¹ (åŒ…å« Waist 66/Size 0 çš„å·®å¼‚åŒ–)...")

    anchors = []

    # ç‰¹ä¾‹ 1: Waist 66, Size 0 -> Tops=Fit, Bottoms=Small
    # Tops (Fit)
    anchors.append(pd.DataFrame({
        'size': [0] * 3000, 'waist': [66] * 3000, 'height_cm': [160] * 3000,
        'hips': [66 * 1.4] * 3000, 'bra_num': [32] * 3000, 'cup_size': 'b', 'category': 'tops', 'target': 1
    }))
    # Bottoms (Small)
    anchors.append(pd.DataFrame({
        'size': [0] * 3000, 'waist': [66] * 3000, 'height_cm': [160] * 3000,
        'hips': [66 * 1.4] * 3000, 'bra_num': [32] * 3000, 'cup_size': 'b', 'category': 'bottoms', 'target': 0
    }))

    # ç‰¹ä¾‹ 2: Waist 78, Size 3 -> All Fit (æ‚¨çš„é»„é‡‘æ ‡å‡†)
    for cat in ['dresses', 'tops', 'bottoms']:
        anchors.append(pd.DataFrame({
            'size': [3] * 2000, 'waist': [78] * 2000, 'height_cm': [165] * 2000,
            'hips': [78 * 1.4] * 2000, 'bra_num': [34] * 2000, 'cup_size': 'b', 'category': cat, 'target': 1
        }))

    df_anchors = pd.concat(anchors)

    # ---------------------------------------------------------
    # 4. åˆå¹¶ä¸è®­ç»ƒ
    # ---------------------------------------------------------
    df_final = pd.concat([df_dresses, df_tops, df_bottoms, df_anchors], ignore_index=True)
    df_final['bmi_proxy'] = df_final['waist'] / df_final['height_cm']
    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)

    features = ['cup_size', 'bra_num', 'hips', 'waist', 'category', 'size', 'height_cm', 'bmi_proxy']
    X = df_final[features]
    y = df_final['target']

    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), ['bra_num', 'hips', 'waist', 'size', 'height_cm', 'bmi_proxy']),
        ('cat', OneHotEncoder(handle_unknown='ignore'), ['cup_size', 'category'])
    ])

    pipeline = Pipeline(steps=[
        ('pre', preprocessor),
        ('clf', XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=10))
    ])

    print("ğŸ‹ï¸ [3/4] è®­ç»ƒ V14 æ¨¡å‹...")
    pipeline.fit(X, y)

    print("ğŸ’¾ [4/4] ä¿å­˜æ¨¡å‹...")
    if not os.path.exists('models'): os.makedirs('models')
    joblib.dump(pipeline, 'models/fit_model.pkl')
    print("ğŸ‰ V14 æ¨¡å‹å·²ä¿å­˜ï¼(å·²å¯ç”¨å·®å¼‚åŒ–å®¹å¿åº¦)")

    # --- è‡ªæµ‹ ---
    print("\nğŸ” --- æœ€ç»ˆè‡ªæµ‹ (Waist 66, Size 0) ---")
    test_inputs = [
        {'cat': 'tops', 'exp': 'Fit'},  # åº”è¯¥åˆèº«
        {'cat': 'bottoms', 'exp': 'Small'}  # åº”è¯¥åå°
    ]
    labels = {0: 'Small', 1: 'Fit', 2: 'Large'}

    for t in test_inputs:
        row = pd.DataFrame({
            'cup_size': ['b'], 'bra_num': [32], 'hips': [66 * 1.4], 'waist': [66],
            'category': [t['cat']], 'size': [0], 'height_cm': [160], 'bmi_proxy': [66 / 160]
        })
        pred = pipeline.predict(row)[0]
        res = labels[pred]
        print(f"Category: {t['cat']:<8} -> {res} (Exp: {t['exp']})")


if __name__ == "__main__":
    train_engine()