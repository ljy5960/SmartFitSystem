import pandas as pd
import numpy as np
import joblib
import os
from xgboost import XGBClassifier
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline


def train_engine():
    print("ğŸš€ [1/4] å¼€å§‹è®­ç»ƒ... (V10: å…¨çŸ©é˜µç½‘æ ¼è®­ç»ƒç‰ˆ)")

    # ---------------------------------------------------------
    # 1. æ„å»ºå…¨é€»è¾‘ç½‘æ ¼ (Grid Matrix)
    # ---------------------------------------------------------
    # æˆ‘ä»¬éå†æ‰€æœ‰å¯èƒ½çš„ è…°å›´(60-100) å’Œ å°ºç (0-14) ç»„åˆ
    # å½»åº•æ¶ˆé™¤æ¨¡å‹çš„â€œç›²åŒºâ€

    grid_data = []

    # éå†å°ºç  0 åˆ° 14
    for s in range(15):
        # éå†è…°å›´ 55 åˆ° 105 (æ­¥é•¿ 1cm)
        for w in range(55, 106):

            # --- æ ¸å¿ƒæ ‡å‡†å…¬å¼ (V9é€»è¾‘) ---
            # Size 0=60, Size 3=78 (æ¯ç å·®6cm)
            std_waist = 60 + (s * 6.0)

            diff = w - std_waist

            # åˆ¤å®šé€»è¾‘
            target = 1  # é»˜è®¤ Fit

            if diff > 4:
                # äººæ¯”è¡£æœå¤§ 4cm ä»¥ä¸Š -> è¡£æœå°äº†
                target = 0  # Small
            elif diff < -4:
                # äººæ¯”è¡£æœå° 4cm ä»¥ä¸Š -> è¡£æœå¤§äº†
                target = 2  # Large

            # --- ç‰¹æ®Šç‰©ç†é” ---
            # Size 0 å’Œ 1 å¾ˆéš¾â€œåå¤§â€(Large)ï¼Œé™¤éè…°å›´æç»†(<55)
            # å¦‚æœåˆ¤å®šä¸º Large ä½† Size <= 1ï¼Œå¼ºåˆ¶çº æ­£ä¸º Fit (é˜²æ­¢è¯¯åˆ¤)
            if target == 2 and s <= 1:
                target = 1

            # ç”Ÿæˆä¸€æ‰¹æ ·æœ¬ (å¢åŠ ä¸€ç‚¹ç‚¹éšæœºæ‰°åŠ¨ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ)
            n_repeat = 50  # æ¯ä¸ªç‚¹ç”Ÿæˆ 50 æ¡æ•°æ®

            batch = pd.DataFrame({
                'size': [s] * n_repeat,
                'height_cm': [165] * n_repeat,  # æ ‡å‡†èº«é«˜
                'waist': np.random.normal(w, 0.5, n_repeat),  # ç´§è´´ç½‘æ ¼ç‚¹
                'hips': np.random.normal(w * 1.4, 1.0, n_repeat),  # ä¸¥æ ¼å…³è”è‡€å›´
                'bra_num': [34] * n_repeat,
                'cup_size': 'b',
                'category': 'dresses',
                'target': target
            })
            grid_data.append(batch)

    print("ğŸ§© ç½‘æ ¼æ„å»ºå®Œæˆï¼Œæ­£åœ¨åˆå¹¶...")
    df_grid = pd.concat(grid_data)

    # ---------------------------------------------------------
    # 2. åŠ å…¥èƒŒæ™¯å™ªéŸ³æ•°æ® (Background Noise)
    # ---------------------------------------------------------
    # åªæœ‰ç½‘æ ¼æ•°æ®å¯èƒ½ä¼šå¤ªæ­»æ¿ï¼ŒåŠ å…¥ä¸€äº›éšæœºæ•°æ®å¢åŠ æ³›åŒ–èƒ½åŠ›
    n_noise = 10000
    sizes_noise = np.random.randint(0, 15, n_noise)
    waist_noise = np.random.uniform(55, 105, n_noise)

    # åŒæ ·çš„é€»è¾‘æ‰“æ ‡
    std_waist_noise = 60 + (sizes_noise * 6.0)
    diff_noise = waist_noise - std_waist_noise
    targets_noise = np.where(diff_noise > 4, 0, np.where(diff_noise < -4, 2, 1))

    # ç‰©ç†é”
    targets_noise = np.where((targets_noise == 2) & (sizes_noise <= 1), 1, targets_noise)

    df_noise = pd.DataFrame({
        'size': sizes_noise,
        'height_cm': np.random.normal(165, 5, n_noise),
        'waist': waist_noise,
        'hips': waist_noise * 1.4,  # ä¿æŒ hips é€»è¾‘ä¸€è‡´
        'bra_num': 34, 'cup_size': 'b', 'category': 'dresses',
        'target': targets_noise
    })

    # ---------------------------------------------------------
    # 3. åˆå¹¶ä¸è®­ç»ƒ
    # ---------------------------------------------------------
    df_final = pd.concat([df_grid, df_noise], ignore_index=True)

    # è®¡ç®— BMI
    df_final['bmi_proxy'] = df_final['waist'] / df_final['height_cm']
    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)

    print(f"âœ… è®­ç»ƒé›†å‡†å¤‡å®Œæ¯•: {len(df_final)} æ¡ (è¦†ç›–æ‰€æœ‰é€»è¾‘ç»„åˆ)")

    features = ['cup_size', 'bra_num', 'hips', 'waist', 'category', 'size', 'height_cm', 'bmi_proxy']
    X = df_final[features]
    y = df_final['target']

    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), ['bra_num', 'hips', 'waist', 'size', 'height_cm', 'bmi_proxy']),
        ('cat', OneHotEncoder(handle_unknown='ignore'), ['cup_size', 'category'])
    ])

    pipeline = Pipeline(steps=[
        ('pre', preprocessor),
        # å¢åŠ æ·±åº¦åˆ° 10ï¼Œè®©å†³ç­–æ ‘èƒ½å®Œç¾æ‹Ÿåˆæˆ‘ä»¬çš„ç½‘æ ¼é€»è¾‘
        ('clf', XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=10))
    ])

    print("ğŸ‹ï¸ [3/4] è®­ç»ƒ V10 å…¨çŸ©é˜µæ¨¡å‹...")
    pipeline.fit(X, y)

    print("ğŸ’¾ [4/4] ä¿å­˜æ¨¡å‹...")
    if not os.path.exists('models'): os.makedirs('models')
    joblib.dump(pipeline, 'models/fit_model.pkl')
    print("ğŸ‰ V10 æ¨¡å‹å·²ä¿å­˜ï¼")

    # --- è‡ªæµ‹ä»£ç  ---
    print("\nğŸ” --- æ¨¡å‹è‡ªæµ‹ (Self Check) ---")
    test_cases = [
        {'w': 60, 's': 0, 'exp': 'Fit'},
        {'w': 78, 's': 0, 'exp': 'Small'},  # ä¹‹å‰é”™åœ¨è¿™é‡Œ
        {'w': 78, 's': 1, 'exp': 'Small'},  # ä¹‹å‰é”™åœ¨è¿™é‡Œ
        {'w': 78, 's': 3, 'exp': 'Fit'},
        {'w': 78, 's': 4, 'exp': 'Large'},
    ]

    for case in test_cases:
        # æ¨¡æ‹Ÿ app.py çš„è¾“å…¥æ„å»º
        input_row = pd.DataFrame({
            'cup_size': ['b'], 'bra_num': [34],
            'hips': [case['w'] * 1.4], 'waist': [case['w']],
            'category': ['dresses'], 'size': [case['s']],
            'height_cm': [165], 'bmi_proxy': [case['w'] / 165]
        })
        pred = pipeline.predict(input_row)[0]
        labels = {0: 'Small', 1: 'Fit', 2: 'Large'}
        res = labels[pred]
        status = "âœ…" if res == case['exp'] else "âŒ"
        print(f"Waist {case['w']} | Size {case['s']} -> Pred: {res} (Exp: {case['exp']}) {status}")


if __name__ == "__main__":
    train_engine()