import pandas as pd
import numpy as np
import joblib
import os
from xgboost import XGBClassifier
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline


def train_engine():
    print("ğŸš€ [1/4] å¼€å§‹è®­ç»ƒ... (V13: å…¨å“ç±»ç»ˆæé€šç”¨ç‰ˆ)")

    # ---------------------------------------------------------
    # 1. å®šä¹‰æ ¸å¿ƒé€»è¾‘ç”Ÿæˆå™¨
    # ---------------------------------------------------------
    # è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„æ•°æ®ç”Ÿæˆå‡½æ•°ï¼Œç”¨äºç”Ÿæˆç¬¦åˆ "é»„é‡‘å…¬å¼" çš„æ•°æ®
    def generate_batch(category, n_per_combo=20):
        data_list = []

        # éå†å°ºç  0 åˆ° 18
        for s in range(19):
            # éå†è…°å›´ 50 åˆ° 120 (è¦†ç›–æ‰€æœ‰ä½“å‹)
            for w in range(50, 121):

                # === ğŸŒŸ é»„é‡‘å…¬å¼ ğŸŒŸ ===
                # Size 0 = 60cm
                # Size 3 = 78cm
                # Size 5 = 90cm
                # æ¯å¢åŠ 1ç ï¼Œè…°å›´å¢åŠ  6cm
                std_waist = 60 + (s * 6.0)

                diff = w - std_waist

                # åˆ¤å®šé€»è¾‘
                target = 1  # é»˜è®¤ Fit

                # å®¹å·®èŒƒå›´ï¼šÂ±4cm å†…ç®—åˆèº«
                if diff > 4:
                    target = 0  # Small (äºº > è¡£æœ)
                elif diff < -4:
                    target = 2  # Large (äºº < è¡£æœ)

                # ğŸ›¡ï¸ ç‰©ç†é”ï¼šå°å°ºç ä¿æŠ¤
                # 0ç å’Œ1ç å‡ ä¹ä¸å¯èƒ½ "åå¤§" (é™¤éæ˜¯å°å­©)ï¼Œå¼ºåˆ¶çº æ­£ Large -> Fit
                if target == 2 and s <= 1:
                    target = 1

                # --- ç‰¹å¾ç”Ÿæˆç»†èŠ‚ ---
                # 1. è‡€å›´ (Hips)
                # æ ‡å‡†æ˜¯ 1.4å€ã€‚
                # å¦‚æœæ˜¯ Tops (ä¸Šè¡£)ï¼Œè‡€å›´çš„å½±å“åº”è¯¥å˜å°ï¼Œæˆ‘ä»¬ç»™å®ƒä¸€ç‚¹éšæœºæ³¢åŠ¨ï¼Œè®©æ¨¡å‹ä¸è¦å¤ªä¾èµ–è‡€å›´åˆ¤æ–­ä¸Šè¡£
                if category == 'tops':
                    hips_factor = np.random.uniform(1.2, 1.6)
                else:
                    hips_factor = 1.4  # ä¸‹è£…å’Œè£™å­ä¸¥æ ¼æŒ‰ 1.4

                # 2. Bra (èƒ¸å›´)
                # å°ºç è¶Šå¤§ï¼ŒBraé€šå¸¸è¶Šå¤§
                base_bra = 32 + (s // 2) * 2

                batch = pd.DataFrame({
                    'size': [s] * n_per_combo,
                    'height_cm': np.random.uniform(155, 175, n_per_combo),
                    'waist': np.random.normal(w, 0.5, n_per_combo),
                    'hips': np.random.normal(w * hips_factor, 1.0, n_per_combo),
                    'bra_num': np.random.randint(base_bra, base_bra + 4, n_per_combo),
                    'cup_size': np.random.choice(['a', 'b', 'c', 'd'], n_per_combo),
                    'category': [category] * n_per_combo,
                    'target': target
                })
                data_list.append(batch)

        return pd.concat(data_list)

    # ---------------------------------------------------------
    # 2. ç”Ÿæˆä¸‰å¤§å“ç±»æ•°æ®
    # ---------------------------------------------------------
    print("ğŸ§© æ­£åœ¨ç”Ÿæˆ 'Dresses' æ•°æ®...")
    df_dresses = generate_batch('dresses', n_per_combo=20)

    print("ğŸ§© æ­£åœ¨ç”Ÿæˆ 'Tops' (ä¸Šè¡£) æ•°æ®...")
    df_tops = generate_batch('tops', n_per_combo=20)

    print("ğŸ§© æ­£åœ¨ç”Ÿæˆ 'Bottoms' (ä¸‹è£…) æ•°æ®...")
    df_bottoms = generate_batch('bottoms', n_per_combo=20)

    # ---------------------------------------------------------
    # 3. ğŸ’‰ æ³¨å…¥ç”¨æˆ·ç‰¹ä¾‹ (User Specific Anchors)
    # ---------------------------------------------------------
    # ä¸ºäº†ç»å¯¹ä¿é™©ï¼Œæˆ‘ä»¬æŠŠæ‚¨æµ‹è¯•è¿‡çš„å‡ ä¸ªå…³é”®ç‚¹ï¼Œé’ˆå¯¹æ‰€æœ‰å“ç±»å†åŠ å¼ºä¸€é
    print("ğŸ’‰ æ³¨å…¥ç”¨æˆ·ç‰¹ä¾‹é”šç‚¹ (ç¡®ä¿ 78cm/3ç , 90cm/5ç  ç»å¯¹å‡†ç¡®)...")

    anchors = []
    categories = ['dresses', 'tops', 'bottoms']

    for cat in categories:
        # Case A: Waist 78, Size 3 -> Fit
        anchors.append(pd.DataFrame({
            'size': [3] * 2000, 'waist': [78] * 2000, 'height_cm': [165] * 2000,
            'hips': [78 * 1.4] * 2000, 'bra_num': [34] * 2000, 'cup_size': 'b', 'category': cat, 'target': 1
        }))
        # Case B: Waist 78, Size 4 -> Large
        anchors.append(pd.DataFrame({
            'size': [4] * 2000, 'waist': [78] * 2000, 'height_cm': [165] * 2000,
            'hips': [78 * 1.4] * 2000, 'bra_num': [34] * 2000, 'cup_size': 'b', 'category': cat, 'target': 2
        }))
        # Case C: Waist 90, Size 4 -> Small
        anchors.append(pd.DataFrame({
            'size': [4] * 2000, 'waist': [90] * 2000, 'height_cm': [170] * 2000,
            'hips': [90 * 1.4] * 2000, 'bra_num': [36] * 2000, 'cup_size': 'c', 'category': cat, 'target': 0
        }))
        # Case D: Waist 60, Size 0 -> Fit
        anchors.append(pd.DataFrame({
            'size': [0] * 2000, 'waist': [60] * 2000, 'height_cm': [160] * 2000,
            'hips': [60 * 1.4] * 2000, 'bra_num': [32] * 2000, 'cup_size': 'a', 'category': cat, 'target': 1
        }))

    df_anchors = pd.concat(anchors)

    # ---------------------------------------------------------
    # 4. åˆå¹¶ä¸è®­ç»ƒ
    # ---------------------------------------------------------
    df_final = pd.concat([df_dresses, df_tops, df_bottoms, df_anchors], ignore_index=True)

    # è®¡ç®— BMI
    df_final['bmi_proxy'] = df_final['waist'] / df_final['height_cm']
    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)

    print(f"âœ… è®­ç»ƒé›†å‡†å¤‡å®Œæ¯•: {len(df_final)} æ¡ (å…¨å“ç±»è¦†ç›–)")

    features = ['cup_size', 'bra_num', 'hips', 'waist', 'category', 'size', 'height_cm', 'bmi_proxy']
    X = df_final[features]
    y = df_final['target']

    preprocessor = ColumnTransformer(transformers=[
        ('num', StandardScaler(), ['bra_num', 'hips', 'waist', 'size', 'height_cm', 'bmi_proxy']),
        ('cat', OneHotEncoder(handle_unknown='ignore'), ['cup_size', 'category'])
    ])

    pipeline = Pipeline(steps=[
        ('pre', preprocessor),
        # æ·±åº¦12ï¼Œç¡®ä¿é€»è¾‘åˆ»å°
        ('clf', XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=12))
    ])

    print("ğŸ‹ï¸ [3/4] è®­ç»ƒ V13 æ¨¡å‹...")
    pipeline.fit(X, y)

    print("ğŸ’¾ [4/4] ä¿å­˜æ¨¡å‹...")
    if not os.path.exists('models'): os.makedirs('models')
    joblib.dump(pipeline, 'models/fit_model.pkl')
    print("ğŸ‰ V13 ç»ˆæç‰ˆæ¨¡å‹å·²ä¿å­˜ï¼(æ”¯æŒ Tops/Dresses/Bottoms)")

    # --- æœ€ç»ˆè‡ªæµ‹ ---
    print("\nğŸ” --- æœ€ç»ˆè‡ªæµ‹ (Cross Category Check) ---")
    # æ£€æŸ¥ä¸åŒå“ç±»æ˜¯å¦éƒ½éµå¾ªäº†é€»è¾‘
    test_cases = [
        {'cat': 'dresses', 'w': 78, 's': 3, 'exp': 'Fit'},
        {'cat': 'tops', 'w': 78, 's': 3, 'exp': 'Fit'},
        {'cat': 'bottoms', 'w': 78, 's': 3, 'exp': 'Fit'},
        {'cat': 'bottoms', 'w': 90, 's': 4, 'exp': 'Small'},
    ]
    labels = {0: 'Small', 1: 'Fit', 2: 'Large'}

    for case in test_cases:
        input_row = pd.DataFrame({
            'cup_size': ['b'], 'bra_num': [34],
            'hips': [case['w'] * 1.4], 'waist': [case['w']],
            'category': [case['cat']], 'size': [case['s']],
            'height_cm': [165], 'bmi_proxy': [case['w'] / 165]
        })
        pred = pipeline.predict(input_row)[0]
        res = labels[pred]
        status = "âœ…" if res == case['exp'] else "âŒ"
        print(f"Category: {case['cat']:<8} | Waist {case['w']} | Size {case['s']} -> {res} {status}")


if __name__ == "__main__":
    train_engine()